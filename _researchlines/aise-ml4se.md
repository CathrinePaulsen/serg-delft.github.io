---
layout: research-line
title: "Machine Learning for Software Engineering"
description: How can machine/deep learning be used to improve complex software development tasks and increase developer productivity?
responsible: "Maliheh Izadi"
---

### Broad Topic Categories
- AI-enabled Software Engineering (AISE)
- Large language models (LLMs) for Code (opportunities and challenges)
- Intelligent development tools
- Enhanced developer productivity


### Research Description

In recent years, Machine Learning and AI technologies have made remarkable stridesâ€”particularly with the emergence of Large Language Models (LLMs) such as GitHub Copilot, Cursor.ai, ChatGPT, JetBrains AI Assistant, Google Gemini, and many others. These models have found successful applications across various domains, including Software Engineering, where software repositories provide a rich archive of valuable data: source code, execution traces, version histories, mailing lists, and bug reports. This wealth of information reflects the evolution and status of software projects and has been leveraged by LLMs to build powerful tools that boost developer productivity, efficiency, and velocity.

Most recently, Transformer-based LLMs and other deep neural networks have been employed to tackle key challenges in Software Engineering, such as code generation, automated program repair, code summarization, structural code representations, and defect prediction.

At the [AISE Lab](https://github.com/AISE-TUDelft), our research explores several topics at the intersection of AI and Software Engineering, including:

- **LLMs for Code Generation, Summarization, Refactoring, and Bug Fixing**: Leverage LLMs to accelerate various development tasks.
- **Human-AI Collaboration in IDEs**: Design intuitive IDE interfaces and workflows that foster seamless collaboration between developers and GenAI assistants, maximizing productivity and usability.
- **Explainability in Code LLMs**: Improve the transparency of LLM-generated suggestions to enhance developer trust and facilitate understanding of model behavior.
- **Mitigating Memorization and Hallucination**: Investigate strategies to reduce factual inaccuracies, hallucinated code, and overfitting in LLM outputs, ensuring reliability in practical applications.
- **Domain-Specific Adaptation of LLMs**: Fine-tune models to specific domains or codebases to improve contextual relevance, precision, and performance.
- **Longitudinal Evaluation and Benchmarking of Code LLMs**: Study the long-term performance of LLMs across languages, tools, and developer workflows. Develop comprehensive benchmarks to assess and compare LLM effectiveness in diverse software engineering tasks.
- **Autonomous Software Engineering Agents**: Build intelligent, task-driven agents capable of independently executing and managing software engineering workflows.
- **Automated Issue-Commit Linking**: Develop techniques to automatically associate commits with relevant issues, enhancing traceability and project maintainability.
- **Intelligent Issue Report Management**: Automate issue triaging, assignment, and resolution support using LLMs to streamline project workflows and boost developer efficiency.
- **Automated Documentation Generation**: Use LLMs to synthesize high-quality, human-readable documentation from codebases, commit history, and other project artifacts.


### Industrial Collaborators/Funding
- Two fully-funded PhD positions funded by **JetBrains Research** through the AI4SE ICAI lab. Maliheh is leading two tracks; namely, [LLM adaptation for coding tasks][ai4se-track2] (track 2) and [Interactive and Aligned IDEs in the LLM Era][ai4se-track3] (track 3).
- **Amazon Research Award** (personal grant) on ["Understanding and Regulating Memorization in Large Language Models for Code"][amazon-award]

### Awards
- **ACM Distinguished Paper Award** at AIWare 2024 conference for our work on "A Transformer-Based Approach for Smart Invocation of Automatic Code Completion"
- **Best Tool Award** at NLBSE for code comment classification (2023)
- **Best Attack** for extracting training data from LLMs at the SatML conference (2023).
- **Best Tool Award** at NLBSE for issue report management (2022).


### Thesis and Publications lists
You can find relevant [AISE BSc and MSc theses][mali-theses] in the TU Delft repository.
Additionally, you can find our recent publications [here][mali-scholar].

### Related MSc Courses:
[CS4570: Machine Learning for Software Engineering][ml4se-course]
Offered in both CS and DSAIT MSc programs.

### AISE Team (Lab Manager: [Maliheh Izadi][mali-website])
#### PhD students
- 2025: Razvan Popescu
- 2024: [Ziyou Li][ziyou]
- 2024: [Daniele Cipollone][danielec]
- 2024: [Agnia Sergeyuk][agnias]
- 2024: [Egor Bogomolov][egorb]
- 2023: [Jonathan Katzy][jonathank]
- 2022: [Ali Al-kaswan][alia]

#### MSc Students
- 2025: Nadine Kuo (intern at [JetBrains Research][jetbrains])
- 2025: Venelina Pocheva (intern at [NXP][nxp])
- 2025: Yash Mundhra (intern at [ASML][asml])

#### Research Assistants
- 2024-2025: Roham Koohestani

#### Alumni
- 2025: Razvan Popescu (MSc student, next a PhD candidate at TU Delft)
- 2024: Andrei Ionesco (interned at [JetBrains Research][jetbrains], next an intern at [Microsoft][microsoft])
- 2023-2024: [Aral de Moor][arald] (BSc student+Scientific developer, next a machine learning engineer at [JetBrains Research][jetbrains])
- 2024: Fabio Salerno (Visiting MSc student), next software engineer at Blue Reply
- 2022-2024: Tim van Dam (MSc student, interned at [JetBrains Research][jetbrains])
- 2022-2024: Frank van der Heijden (MSc student, interned at [JetBrains Research][jetbrains])
- 2023-2024: Philippe de Bekker (MSc student, next software engineer at [Booking.com][booking])
- 2023-2024: Remco Schrijver (MSc student, interned at [JetBrains Research][jetbrains], next software engineer at [Booking.com][booking])
- 2022-2023: Ali Al-kaswan (MSc student, now a PhD candidate at TU Delft)

#### Contact
If you have questions or are interested in joining the AISE lab, please reach out to [Maliheh Izadi](mailto:m.izadi@tudelft.nl).

[mali-website]: https://malihehizadi.github.io/PersonalWebsite/
[alia]: https://aalkaswan.github.io/
[jonathank]: https://jkatzy.nl/
[egorb]: https://scholar.google.com/citations?user=rxacRcwAAAAJ&hl=en
[agnias]: https://scholar.google.com/citations?user=EHnCIIwAAAAJ&hl=en
[arald]: https://aral.cc/
[danielec]: https://www.linkedin.com/in/dancip00/
[ziyou]: https://li-ziyou.github.io/
[nxp]: https://www.nxp.com/
[asml]: https://www.asml.nl/
[jetbrains]: https://www.jetbrains.com/research/
[microsoft]: https://www.microsoft.com/
[booking]: https://www.booking.com/
[mali-theses]: https://repository.tudelft.nl/search?object_type=master_thesis%2Bbachelor_thesis%2Bstudent_report&search_by=content&keyword=&collection=&file_extension=&search_term=maliheh+izadi
[mali-scholar]: https://scholar.google.com/citations?user=F2D5RawAAAAJ&hl=en
[ai4se-website]: https://se.ewi.tudelft.nl/ai4se/
[ai4se-track2]: https://se.ewi.tudelft.nl/ai4se/tracks/02_llm_adaptation.html
[ai4se-track3]: https://se.ewi.tudelft.nl/ai4se/tracks/03_interactive_aligned_ide.html
[amazon-award]: https://www.amazon.science/research-awards/recipients/maliheh-izadi
[ml4se-course]: https://studiegids.tudelft.nl/a101_displayCourse.do?course_id=51117
